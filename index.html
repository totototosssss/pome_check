<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Pome Classify</title>
    
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/knn-classifier"></script>

    <script src="https://www.gstatic.com/firebasejs/9.23.0/firebase-app-compat.js"></script>
    <script src="https://www.gstatic.com/firebasejs/9.23.0/firebase-firestore-compat.js"></script>

    <style>
        :root {
            --bg: #ffffff;
            --text: #1d1d1f;
            --sub-text: #86868b;
            --accent: #000000;
            --btn-bg: #f5f5f7;
            --radius: 18px;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "SF Pro Text", "Helvetica Neue", sans-serif;
            background-color: var(--bg);
            color: var(--text);
            margin: 0;
            padding: 40px 20px;
            display: flex;
            flex-direction: column;
            align-items: center;
            min-height: 100vh;
            -webkit-font-smoothing: antialiased;
        }

        h1 {
            font-size: 1.5rem;
            font-weight: 600;
            letter-spacing: -0.02em;
            margin: 0 0 40px 0;
            color: var(--text);
        }

        /* 画像エリア */
        .viewport {
            width: 280px;
            height: 280px;
            background-color: var(--btn-bg);
            border-radius: var(--radius);
            margin-bottom: 30px;
            position: relative;
            overflow: hidden;
            box-shadow: 0 10px 30px rgba(0,0,0,0.05);
            transition: transform 0.3s cubic-bezier(0.25, 0.8, 0.25, 1);
        }
        .viewport.active { transform: scale(1.02); box-shadow: 0 20px 40px rgba(0,0,0,0.12); }

        canvas {
            width: 100%; height: 100%;
            display: block;
            opacity: 0;
            transition: opacity 0.5s;
        }
        canvas.show { opacity: 1; }

        .placeholder {
            position: absolute;
            top: 50%; left: 50%;
            transform: translate(-50%, -50%);
            color: var(--sub-text);
            font-size: 0.9rem;
            pointer-events: none;
        }

        /* コントロール */
        .actions {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 12px;
            width: 100%;
            max-width: 320px;
            margin-bottom: 30px;
        }

        button, .file-btn {
            appearance: none;
            border: none;
            background: var(--btn-bg);
            color: var(--text);
            padding: 16px;
            border-radius: 14px;
            font-size: 0.95rem;
            font-weight: 500;
            cursor: pointer;
            text-align: center;
            transition: all 0.2s ease;
            display: flex; align-items: center; justify-content: center;
        }
        .file-btn:active, button:active { transform: scale(0.96); background: #e5e5e5; }
        .primary-btn { background: var(--accent); color: white; }
        .primary-btn:hover { opacity: 0.9; }
        .primary-btn:disabled { opacity: 0.3; cursor: default; transform: none; }
        
        input[type="file"] { display: none; }

        /* 結果表示 */
        #result-area {
            text-align: center;
            opacity: 0;
            transform: translateY(10px);
            transition: all 0.4s ease;
            pointer-events: none; /* 非表示時はクリック不可 */
        }
        #result-area.visible { opacity: 1; transform: translateY(0); pointer-events: auto; }

        .prediction { font-size: 2.5rem; font-weight: 700; letter-spacing: -0.03em; margin-bottom: 5px; }
        .confidence { color: var(--sub-text); font-size: 0.85rem; margin-bottom: 25px; }

        /* 学習ボタン群 */
        .teach-grid {
            display: grid;
            grid-template-columns: repeat(4, 1fr);
            gap: 8px;
            width: 100%;
            max-width: 380px;
        }
        .teach-btn {
            font-size: 0.8rem;
            padding: 12px 0;
            background: white;
            border: 1px solid #e5e5e5;
            box-shadow: 0 2px 5px rgba(0,0,0,0.02);
        }
        .teach-btn:hover { border-color: var(--accent); }

        /* ステータス & オーバーレイ */
        .status-bar {
            position: fixed; bottom: 20px;
            font-size: 0.75rem; color: #c7c7cc;
            font-family: monospace;
        }

        /* 全画面オーバーレイ（完了通知） */
        #overlay {
            position: fixed; inset: 0;
            background: rgba(255,255,255,0.9);
            backdrop-filter: blur(5px);
            display: flex; align-items: center; justify-content: center;
            flex-direction: column;
            opacity: 0; pointer-events: none;
            transition: opacity 0.3s;
            z-index: 999;
        }
        #overlay.show { opacity: 1; pointer-events: auto; }
        .overlay-icon { font-size: 3rem; margin-bottom: 10px; transform: scale(0.5); transition: transform 0.4s cubic-bezier(0.175, 0.885, 0.32, 1.275); }
        #overlay.show .overlay-icon { transform: scale(1); }
        .overlay-text { font-weight: 600; font-size: 1.2rem; }

    </style>
</head>
<body>

    <h1>Pome Classify</h1>

    <div class="viewport" id="viewport">
        <div class="placeholder">Select Image</div>
        <canvas id="canvas"></canvas>
    </div>

    <div class="actions">
        <label class="file-btn">
            Photo
            <input type="file" id="file-input" accept="image/*">
        </label>
        <button id="predict-btn" class="primary-btn" disabled>Identify</button>
    </div>

    <div id="result-area">
        <div class="prediction" id="pred-label"></div>
        <div class="confidence" id="pred-conf"></div>

        <div class="teach-grid">
            <button class="teach-btn" onclick="teach('もち')">もち</button>
            <button class="teach-btn" onclick="teach('しらたま')">しらたま</button>
            <button class="teach-btn" onclick="teach('きなこ')">きなこ</button>
            <button class="teach-btn" onclick="teach('くろみつ')">くろみつ</button>
        </div>
        <div style="font-size:0.7rem; color:#ccc; margin-top:10px;">Tap correct name to train</div>
    </div>

    <div class="status-bar" id="status">Initializing Neural Engine...</div>

    <div id="overlay">
        <div class="overlay-icon">✓</div>
        <div class="overlay-text">Learning Complete</div>
    </div>

    <script>
        // ==========================================
        // 1. Configuration & Setup
        // ==========================================
        const firebaseConfig = {
            apiKey: "AIzaSyDKcFzyED8hWVUdJR0FDmWFOl0UWzOWN3U",
            authDomain: "pome-c99ca.firebaseapp.com",
            projectId: "pome-c99ca",
            storageBucket: "pome-c99ca.firebasestorage.app",
            messagingSenderId: "621942148142",
            appId: "1:621942148142:web:09bd19ee5b0d0782eaa3bf",
            measurementId: "G-9SMH547T55"
        };

        firebase.initializeApp(firebaseConfig);
        const db = firebase.firestore();

        // Variables
        let net;
        let classifier;
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const statusEl = document.getElementById('status');
        const resultArea = document.getElementById('result-area');
        const predictBtn = document.getElementById('predict-btn');
        const overlay = document.getElementById('overlay');
        const viewport = document.getElementById('viewport');

        // ==========================================
        // 2. Core Logic (The "Supreme" ML)
        // ==========================================
        
        async function init() {
            try {
                // MobileNet V2 (Alpha 1.0) for maximum accuracy
                net = await mobilenet.load({ version: 2, alpha: 1.0 });
                classifier = knnClassifier.create();
                
                statusEl.innerText = "Syncing with Cloud Brain...";
                await loadData();
                
                statusEl.innerText = "Ready";
            } catch (e) {
                statusEl.innerText = "Error: " + e.message;
            }
        }

        async function loadData() {
            // Load latest 800 examples
            const snapshot = await db.collection('dataset_v3').orderBy('timestamp', 'desc').limit(800).get();
            if (snapshot.empty) return;
            
            snapshot.forEach(doc => {
                try {
                    const data = doc.data();
                    const tensor = tf.tensor(JSON.parse(data.features));
                    classifier.addExample(tensor, data.label);
                    tensor.dispose();
                } catch(e) {}
            });
        }

        // ==========================================
        // 3. Interaction & Prediction
        // ==========================================

        document.getElementById('file-input').addEventListener('change', (e) => {
            const file = e.target.files[0];
            if (!file) return;

            const reader = new FileReader();
            reader.onload = (event) => {
                const img = new Image();
                img.src = event.target.result;
                img.onload = () => {
                    // Center Crop & Draw
                    const size = Math.min(img.width, img.height);
                    const sx = (img.width - size) / 2;
                    const sy = (img.height - size) / 2;

                    canvas.width = 224; canvas.height = 224;
                    ctx.drawImage(img, sx, sy, size, size, 0, 0, 224, 224);
                    
                    canvas.classList.add('show');
                    predictBtn.disabled = false;
                    resultArea.classList.remove('visible'); // Hide previous result
                    viewport.classList.add('active');
                    statusEl.innerText = "Image Loaded";
                }
            };
            reader.readAsDataURL(file);
        });

        predictBtn.addEventListener('click', async () => {
            if (!net) return;
            statusEl.innerText = "Analyzing...";
            predictBtn.disabled = true;

            const imgTensor = tf.browser.fromPixels(canvas);
            const activation = net.infer(imgTensor, 'conv_preds');

            if (classifier.getNumClasses() > 0) {
                // K=7 for stability
                const result = await classifier.predictClass(activation, 7);
                
                const label = result.label;
                const conf = result.confidences[label] ? Math.floor(result.confidences[label] * 100) : 0;

                document.getElementById('pred-label').innerText = label;
                document.getElementById('pred-conf').innerText = `${conf}% Confidence`;
                resultArea.classList.add('visible');
            } else {
                document.getElementById('pred-label').innerText = "Unknown";
                document.getElementById('pred-conf').innerText = "No training data yet";
                resultArea.classList.add('visible');
            }

            // Cleanup
            imgTensor.dispose();
            activation.dispose(); // We re-compute during teaching for augmentation
            predictBtn.disabled = false;
            statusEl.innerText = "Done";
        });

        // ==========================================
        // 4. Learning (Triple Augmentation)
        // ==========================================
        
        window.teach = async function(label) {
            statusEl.innerText = "Training...";
            
            // Generate Tensors
            // 1. Original
            const imgTensor = tf.browser.fromPixels(canvas);
            
            // 2. Flipped (左右反転)
            const flippedTensor = imgTensor.reverse(2);
            
            // 3. Brightness Adjusted (少し明るくする) - Robustness against lighting
            // Values are int32 [0, 255]. Add 20 brightness. Clip to 255.
            const brightTensor = tf.tidy(() => {
                return imgTensor.add(tf.scalar(20)).clipByValue(0, 255).cast('int32');
            });

            // Process Batch
            const tensors = [imgTensor, flippedTensor, brightTensor];
            const tags = ["original", "flip", "bright"];
            const batch = db.batch();

            try {
                for (let i = 0; i < tensors.length; i++) {
                    const t = tensors[i];
                    const activation = net.infer(t, 'conv_preds');
                    
                    // Local Learn
                    classifier.addExample(activation, label);

                    // Cloud Save
                    const features = await activation.array();
                    const ref = db.collection('dataset_v3').doc();
                    batch.set(ref, {
                        label: label,
                        features: JSON.stringify(features),
                        timestamp: firebase.firestore.FieldValue.serverTimestamp(),
                        augType: tags[i]
                    });

                    activation.dispose();
                }

                await batch.commit();

                // UI Feedback
                overlay.classList.add('show');
                setTimeout(() => {
                    overlay.classList.remove('show');
                }, 1500);
                
                statusEl.innerText = "Saved (x3 Augmented)";

            } catch (e) {
                console.error(e);
                alert("Save Failed");
            } finally {
                // Cleanup Tensors
                imgTensor.dispose();
                flippedTensor.dispose();
                brightTensor.dispose();
            }
        };

        init();
    </script>
</body>
</html>
